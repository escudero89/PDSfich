[[ INTRODUCCIÓN ]]

Las señales voz pueden ser clasificadas en tres diferentes regiones: sonoras, sordas y de silencio.

Cuando se habla, el pecho se expande y se contrae, forzando al aire de los pulmones a salir a través de la traquea. Cuando este pasa por las cuerdas vocales, si las mismas estaban tensadas (para producir vocales, por ejemplo), se produce entonces una modulación de la voz en forma de un tren de impulsos cuasi-periódico, y el resultado es un sonido sonoro. En el caso de que las cuerdas vocales estuvieran distendidas, se producen sonidos sordos.

La vibración de las cuerdas vocales produce ondas sonoras con un espectro de frecuencia bastante distribuido, estas son filtradas por el tracto vocal y algunas frecuencias son reforzadas y otras atenuadas, dependiendo de la configuración de los articuladores. Las frecuencias fuertemente reforzadas son precisamente los “formantes” principales de la emisión sonora.

El formante con la frecuencia más baja se designa F1, el segundo F2, el tercero F3, etc. Aunque sólo son necesarios los tres primeros formantes para caracterizar el sonido que se escucha, el resto de los formantes de más alto orden son necesarios para producir un sonido de buena calidad. En una persona, los formantes de alto orden determinan propiedades acústicas, como lo es el timbre.

'''
Una vez que el aire sale a través de la boca o de la nariz (o ambos) este es percibido como habla.

La suposición básica de casi todos los sistemas de procesamiento de señales de voz es que la fuente de excitación y el sistema de cuerdas vocales son independientes.
'''

Las regiones sonoras se comportan como señales cuasi-periódicas en el dominio temporal. Si tomamos segmentos de una señal de voz, podemos tratar a estas como periódicas en términos prácticos para su análisis y procesamiento. La periodicidad asociada a cada segmento está definido como el “pitch de período T0” en el dominio temporal, y “frecuencia fundamental F0” en el dominio de la frecuencia. 

Específicamente, el término pitch hace referencia a la unidad percibida de la frecuencia fundamental. Contiene  información importante sobre el hablante, y también es importante para la tarea de analizar una señal. Es por eso que la estimación del pitch es una de las tareas más importantes en el procesamiento de la voz.

Hay una gran cantidad de métodos diseñados para estimar el pitch dentro del área del procesamiento de voz. Entre los métodos más usados tenemos la auto-correlación de la voz, la determinación del pitch mediante el cepstrum, y la SIFT pitch estimation (VER ESTO).


== DESARROLLO ==

1º) Agarramos la señal de voz, la dividimos en ventanas de 40ms de Hamming, y nos fijamos la energía y la cantidad de veces que corta la gráfica (AVERIGUAR VALORES).

===== ESTIMACION POR AUTOCORRELACION =====

2º) Para estimar pitch por autocorrelacion, tomamos la mitad de la gráfica (en donde en 0 está la máxima energía) y buscamos el segundo pico. Una vez encontrado, sabemos que esta en X muestra. Como la autocorrelacion esta en el dominio temporal, hacemos X*Tm para obtener el valor en ms, y 1/(X*Tm) para obtener el pitch en Hertz.

Since autocorrelation sequence is symmetric with respect to zero lag, only postiove lag values are shown in the figure.

The second largest peak is the autocorrelation sequence, represents To and 
can be picked up easily by a simple peak picking algorithm compared to finding 'To' from the speech segment itself. Hence autocorrelation method is preferred over other direct methods of pitch estimation from speech.

There is no prominent peak as in the case of voiced speech. This is the fundamental distinction between voiced and unvoiced speech.

Further, human speech pitch is typically in the range 100-400 Hz and accordingly the pitch in the range 2.5-10 msec. Therefore for the estimation of pitch the largest peak in the partial autocorrelation sequence starting from 2.5 msec lag is ..... out and its distance with respect to zero lag is measured as pitch peak 'To '. This is illustrated in Fig 3. Once we know To , then pitch can be computed as ..... , where Fs isthe sampling frequency of the speech signal and 'To ' is pitch period in samples.

===== ESTIMACION POR CEPSTRUM =====

1º) Agarramos la señal, le hacemos la ifft(abs(log(fft(S))), y tomamos la mitad izquierda (por ser simetrica).

2º) En la quefrencia (la variable independiente del Cepstrum) su unidad es el tiempo. Como la voz humana esta en el rango 50~400 Hz, tomo el pico después de los 2 primeros msec (1 / 2msec = 500 Hz).


The main limitation of pitch estimation by the auto correlation of speech is that there may be peaks larger than the peak corresponding to the pitch period T0 due to the .... of the vocal tract, As a result there may be picking of .... peaks and hence wrong estimation of pitch. The approach to minimize such errors is to separate the vocal tract and excitation source related information in the speech signal and there use the source information for pitch estimation. The ceptral analysis of speech provides such an approach.
 
The ceptrum of speech is defined as the inverse Fourier transform of the log magnitude spectrum. The cepstrum projects all the slowly varying components in log magnitude spectrum to the low frequency region and fast varying components to the high frequency regions. In the log magnitude spectrum, the slowly varying components represent the envolope corresponds to the vocal tract and the fast varying components to the excitation source. As a result the vocal tract and excitation source components get represented naturally in the spectrum of speech.

Fig. 5 shows a 30 msec segment of unvoiced speech, its log magnitude spectrum and cepstrum. The initial 13-15 values represent the vocal tract information and later ... about the excitation source. By comparing Fig 4 and Fig. 5 it may be observed that there is no prominent peak in case of ceptrum of unvoiced speech after the 13-15 initial cepstral values. This is the main distinction between cepstrum of voiced and unvoiced speech. This observation also ... a method for cepstrum pitch determination. For the estimation of pitch, the target peak in the cepstral sequence after initial 2 msec  .....16 cepstral values, gives the estimation of pitch period in case of voiced speech. This is illustrated in Fig. 6.

== DUDAS ==

* La estimacion del pitch debe obtener un valor, o una grafica con valores tomados?

* Averiguar valores: Agarramos la señal de voz, la dividimos en ventanas de 40ms de Hamming, y nos fijamos la energía y la cantidad de veces que corta la gráfica.

* Además del método de autocorrelación, y cepstrum, hay otro mas que debo implementar?

* Rango de la voz humana es 50~400hz?